{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import hypergeom\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "# personal modules\n",
    "import databases as db\n",
    "import kuzmin_data_2018 as data_2018\n",
    "import kuzmin_data_2020 as data_2020\n",
    "import enrichment as enrich\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "dataset = \"Kuzmin2020\" # Kuzmin2020 or Kuzmin2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "if dataset == \"Kuzmin2018\":\n",
    "    kuzmin_2018_data_dir = \"/Users/bjarnold/Princeton_DataX/Epistasis/higher_order_reanalysis/yeast_screens/KuzminEtAl2018/data_files\"\n",
    "    kuzmin_2018_s1, kuzmin_2018_s1_digenic, kuzmin_2018_s1_trigenic = data_2018.load_kuzmin_2018_s1(kuzmin_2018_data_dir)\n",
    "\n",
    "    costanzo_et_al_data_dir = \"/Users/bjarnold/Princeton_DataX/Epistasis/higher_order_reanalysis/yeast_screens/CostanzoEtAl2016/data_files/Data File S1. Raw genetic interaction datasets: Pair-wise interaction format\"\n",
    "    costanzo_data = data_2018.load_costanzo_data(costanzo_et_al_data_dir)\n",
    "    #kuzmin_2020_s3, kuzmin_2020_s3_digenic = data.load_kuzmin_2020_s3(kuzmin_2020_data_dir)\n",
    "    #kuzmin_2020_s5, kuzmin_2020_s5_singMut, kuzmin_2020_s5_dblMut = data.load_kuzmin_2020_s5(kuzmin_2020_data_dir)\n",
    "    #kuzmin_2020_s2 = data.load_kuzmin_2020_s2(kuzmin_2020_data_dir)\n",
    "\n",
    "\n",
    "    #print(kuzmin_2020_s1.combined_mutant_type.value_counts())\n",
    "    #print(kuzmin_2020_s2.combined_mutant_type.value_counts())\n",
    "\n",
    "\n",
    "    # f_i and f_j taken from costanzo, f_k taken from array allele in kuzmin 2018\n",
    "\n",
    "    f_k_SMF = dict(zip(kuzmin_2018_s1_trigenic.array_allele_name, kuzmin_2018_s1_trigenic.array_single_mutant_fitness))\n",
    "\n",
    "    s1 = pd.concat([costanzo_data.query_allele_name, costanzo_data.array_allele_name], axis=0)\n",
    "    s2 = pd.concat([costanzo_data.query_smf, costanzo_data.array_smf], axis=0)\n",
    "    df = pd.concat([s1, s2], axis=1).rename(columns={0:\"allele\", 1:\"value\"})\n",
    "    df = df.drop_duplicates(subset=[\"allele\"], keep='first').reset_index(drop=True)\n",
    "    f_i_j_SMF = dict(zip(df.allele, df.value))\n",
    "\n",
    "    # f_ij from query fitness in trigenic table\n",
    "    # f_ik and f_jk from fitness digenic table\n",
    "    f_ij_DMF = dict(zip(kuzmin_2018_s1_trigenic.query_allele_name, kuzmin_2018_s1_trigenic.query_single_double_mutant_fitness))\n",
    "    f_ik_jk_DMF = dict(zip(kuzmin_2018_s1_digenic.alleles, kuzmin_2018_s1_digenic.query_single_double_mutant_fitness))\n",
    "\n",
    "    #e_ik and e_jk come from the digenic portion of the Kuzmin 2018 S1 table\n",
    "    e_ik_jk_DMF = dict(zip(kuzmin_2018_s1_digenic.alleles, kuzmin_2018_s1_digenic.raw_interaction_score_epsilon))\n",
    "\n",
    "    f_i, f_j, f_k, f_ij, f_ik, f_jk, e_ik_kuz, e_jk_kuz = data_2018.consolidate_fitnesses_across_2018_tables(kuzmin_2018_s1_trigenic,\n",
    "                                                                                                        f_k_SMF,\n",
    "                                                                                                        f_i_j_SMF,\n",
    "                                                                                                        f_ij_DMF,\n",
    "                                                                                                        f_ik_jk_DMF,\n",
    "                                                                                                        e_ik_jk_DMF)\n",
    "                                                            \n",
    "    df = kuzmin_2018_s1_trigenic\n",
    "\n",
    "if dataset == \"Kuzmin2020\":\n",
    "    kuzmin_2020_data_dir = \"/Users/bjarnold/Princeton_DataX/Epistasis/higher_order_reanalysis/yeast_screens/KuzminEtAl2020\"\n",
    "    kuzmin_2020_s1, kuzmin_2020_s1_digenic, kuzmin_2020_s1_trigenic = data_2020.load_kuzmin_2020_s1(kuzmin_2020_data_dir)\n",
    "    kuzmin_2020_s3, kuzmin_2020_s3_digenic = data_2020.load_kuzmin_2020_s3(kuzmin_2020_data_dir)\n",
    "    kuzmin_2020_s5, kuzmin_2020_s5_singMut, kuzmin_2020_s5_dblMut = data_2020.load_kuzmin_2020_s5(kuzmin_2020_data_dir)\n",
    "    kuzmin_2020_s2 = data_2020.load_kuzmin_2020_s2(kuzmin_2020_data_dir)\n",
    "\n",
    "\n",
    "    print(kuzmin_2020_s1.combined_mutant_type.value_counts())\n",
    "    print(kuzmin_2020_s2.combined_mutant_type.value_counts())\n",
    "\n",
    "    kuzmin_2020_s1_dblMutFit = dict(zip(kuzmin_2020_s1_digenic.alleles, kuzmin_2020_s1_digenic.double_triple_mutant_fitness))\n",
    "    kuzmin_2020_s1_epsilon = dict(zip(kuzmin_2020_s1_digenic.alleles, kuzmin_2020_s1_digenic.raw_interaction_score_epsilon))\n",
    "    kuzmin_2020_s1_singMutFit = dict(zip(kuzmin_2020_s1.array_allele_name, kuzmin_2020_s1.array_single_mutant_fitness))\n",
    "\n",
    "    kuzmin_2020_s3_singMutFit = dict(zip(kuzmin_2020_s3.array_allele_name, kuzmin_2020_s3.array_single_mutant_fitness))\n",
    "\n",
    "    kuzmin_2020_s5_dblMut = kuzmin_2020_s5[kuzmin_2020_s5.mutant_type == \"Double mutant\"]\n",
    "    kuzmin_2020_s5_singMut = kuzmin_2020_s5[kuzmin_2020_s5.mutant_type == \"Single mutant\"]\n",
    "\n",
    "    kuzmin_2020_s5_dblMutFit = dict(zip(kuzmin_2020_s5_dblMut.alleles, kuzmin_2020_s5_dblMut.fitness))\n",
    "    kuzmin_2020_s5_singMutFit = dict(zip(kuzmin_2020_s5_singMut.alleles, kuzmin_2020_s5_singMut.fitness))\n",
    "\n",
    "    f_i, f_j, f_k, f_ij, f_ik, f_jk, e_ik_kuz, e_jk_kuz = data_2020.consolidate_fitnesses_across_tables(kuzmin_2020_s1_trigenic,\n",
    "                                                                                            kuzmin_2020_s1_dblMutFit,\n",
    "                                                                                            kuzmin_2020_s1_singMutFit,\n",
    "                                                                                            kuzmin_2020_s1_epsilon,\n",
    "                                                                                            kuzmin_2020_s3_singMutFit,\n",
    "                                                                                            kuzmin_2020_s5_singMutFit,\n",
    "                                                                                            kuzmin_2020_s5_dblMutFit)\n",
    "\n",
    "    # incorporate fitnesses into the data frame so that for each triplet of genes, we have all relevant fitness values in the same row to calculate interactions\n",
    "    # since we will be mostly using kuzmin_2020_s1_trigenic going forwards, lets rename it to df\n",
    "\n",
    "    df = kuzmin_2020_s1_trigenic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "names = ['f_i', 'f_j', 'f_k', 'f_ij', 'f_ik', 'f_jk', 'e_ik_kuz', 'e_jk_kuz']\n",
    "vars = [f_i, f_j, f_k, f_ij, f_ik, f_jk, e_ik_kuz, e_jk_kuz]\n",
    "for i in range(len(names)):\n",
    "    n = names[i]\n",
    "    v = vars[i]\n",
    "    print(n, \"\\t\", np.sum(np.isnan(np.array([i for i in v.values()]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################\n",
    "\n",
    "AFTER THIS POINT ALL CODE IS REDUNDANT WITH THE 2020 ANALYSIS\n",
    "\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df['f_ij'] = df['alleles'].map(f_ij)\n",
    "df['f_ik'] = df['alleles'].map(f_ik)\n",
    "df['f_jk'] = df['alleles'].map(f_jk)\n",
    "\n",
    "df['f_i'] = df['alleles'].map(f_i)\n",
    "df['f_j'] = df['alleles'].map(f_j)\n",
    "df['f_k'] = df['alleles'].map(f_k)\n",
    "\n",
    "df['e_ik_kuz'] = df['alleles'].map(e_ik_kuz)\n",
    "df['e_jk_kuz'] = df['alleles'].map(e_jk_kuz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(np.sum(~np.isnan(df.f_ij)))\n",
    "print(np.sum(~np.isnan(df.f_ik)))\n",
    "print(np.sum(~np.isnan(df.f_jk)))\n",
    "print(np.sum(~np.isnan(df.f_i)))\n",
    "print(np.sum(~np.isnan(df.f_j)))\n",
    "print(np.sum(~np.isnan(df.f_k)))\n",
    "print()\n",
    "print(np.sum(~np.isnan(df.e_ik_kuz)))\n",
    "print(np.sum(~np.isnan(df.e_jk_kuz)))\n",
    "\n",
    "#print(len(kuzmin_2020_s1_trigenic.f_ik))\n",
    "print(len(df.dropna(subset=['f_i', 'f_j', 'f_k', 'f_ij', 'f_ik', 'f_jk', 'e_ik_kuz', 'e_jk_kuz'])))\n",
    "print(len(df.dropna(subset=['f_i', 'f_j', 'f_k', 'f_ij', 'f_ik', 'f_jk'])))\n",
    "print(len(df))\n",
    "print(len(df.dropna(subset=['f_i', 'f_j', 'f_k', 'f_ij', 'f_ik', 'f_jk']))/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# To ensure we appropriately understand the data, we recalculate tau (trigenic interaction) using the formula in the supplement of Kuzmin 2018.\n",
    "# These values *should* correspond to those reported in the 'adjusted_interaction_score_epsilon_or_tau' column. Around ~1% of recalculated tau values\n",
    "# strongly deviate from those reported, and we filter these out.\n",
    "\n",
    "df = df.dropna(subset=['f_i', 'f_j', 'f_k', 'f_ij', 'f_ik', 'f_jk', 'e_ik_kuz', 'e_jk_kuz'])\n",
    "threshold = 0.1\n",
    "\n",
    "df['tau_kuzmin_orig'] = df.double_triple_mutant_fitness - df.f_ij*df.f_k - df.e_ik_kuz*df.f_j - df.e_jk_kuz*df.f_i\n",
    "\n",
    "# filter out results that aren't reproducible according to the original equation\n",
    "print(\"fraction of tau values that remain after filtering out deviants\")\n",
    "print(len(df[abs(df.tau_kuzmin_orig - df.adjusted_interaction_score_epsilon_or_tau) <= threshold])/len(df))\n",
    "\n",
    "df = df[abs(df.tau_kuzmin_orig - df.adjusted_interaction_score_epsilon_or_tau) <= threshold]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15,5))\n",
    "\n",
    "p = sns.kdeplot(df['adjusted_interaction_score_epsilon_or_tau'], ax=axs[0], color=\"blue\")\n",
    "p = sns.kdeplot(df['tau_kuzmin_orig'], ax=axs[0], color=\"red\")\n",
    "p.set(xlabel='tau (reported blue, recalculated red)')\n",
    "\n",
    "p = sns.regplot(x=df['tau_kuzmin_orig'],\n",
    "            y=df['adjusted_interaction_score_epsilon_or_tau'],\n",
    "            scatter_kws={'alpha':0.01},\n",
    "            line_kws={'color': 'red'},\n",
    "            ax=axs[1])\n",
    "p.set(xlabel='tau recalculated', ylabel='tau reported')\n",
    "\n",
    "df[['tau_kuzmin_orig', 'adjusted_interaction_score_epsilon_or_tau']].corr(method=\"pearson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.loc[:, 'tau_cumulant'] = df.double_triple_mutant_fitness + 2*df.f_i*df.f_j*df.f_k - df.f_i*df.f_jk - df.f_j*df.f_ik - df.f_k*df.f_ij\n",
    "\n",
    "df.loc[:,'e_ik_mult'] = df.f_ik/(df.f_i*df.f_k)\n",
    "df.loc[:,'e_jk_mult'] = df.f_jk/(df.f_j*df.f_k)\n",
    "#df.loc[:,'tau_multiplicative'] = df.double_triple_mutant_fitness/(df.f_ij*df.f_k*df.e_ik_mult*df.e_jk_mult) \n",
    "df.loc[:,'tau_multiplicative'] = (df.double_triple_mutant_fitness*df.f_i*df.f_j*df.f_k)/(df.f_ij*df.f_ik*df.f_jk) \n",
    "\n",
    "\n",
    "\n",
    "# tau_cumulant (forumula from cumulant formula) calculated above should be equivalent to tau_kuzmin_orig (formula from Kuzmin et al 2018).\n",
    "# One can substitute (f_jk - f_j*f_k) for e_jk and (f_ik - f_i*f_k) for e_ik into the Kuzmin et al 2018 formula to get the cumulant formula\n",
    "# However, the results using these two equivalent formula aren't the same because  f_jk != (f_j*f_k + e_jk) and  f_ik != (f_i*f_k + e_ik)\n",
    "\n",
    "# subsituting in (f_j*f_k + e_jk) for f_jk and (f_i*f_k + e_ik) for f_ik\n",
    "# This gives trigenic interaction scores that are similar to reported values, see sanityChecks notebook\n",
    "# newly recalculated double mutant fitnesses, and corresponding interactions, are suffixed with 2\n",
    "\n",
    "df.loc[:, 'f_ik_2'] = df.f_i*df.f_k + df.e_ik_kuz\n",
    "df.loc[:, 'f_jk_2'] = df.f_j*df.f_k + df.e_jk_kuz\n",
    "\n",
    "df.loc[df['f_ik_2'] < 0, ['f_ik_2']] = np.nan\n",
    "df.loc[df['f_jk_2'] < 0, ['f_jk_2']] = np.nan\n",
    "\n",
    "df.loc[:,'e_ik_mult2'] = df.f_ik_2/(df.f_i*df.f_k)\n",
    "df.loc[:,'e_jk_mult2'] = df.f_jk_2/(df.f_j*df.f_k)\n",
    "\n",
    "df.loc[:, 'tau_cumulant2'] = df.double_triple_mutant_fitness + 2*df.f_i*df.f_j*df.f_k - df.f_i*df.f_jk_2 - df.f_j*df.f_ik_2 - df.f_k*df.f_ij\n",
    "\n",
    "# calculate multiplicative results using the custom dbl mutant fitnesses that gave results consistent with those reported (above)\n",
    "# compare these with tau_cumulant2\n",
    "#df.loc[:,'tau_multiplicative2'] = df.double_triple_mutant_fitness/(df.f_ij*df.f_k*df.e_ik_mult2*df.e_jk_mult2) \n",
    "df.loc[:,'tau_multiplicative2'] = (df.double_triple_mutant_fitness*df.f_i*df.f_j*df.f_k)/(df.f_ij*df.f_ik_2*df.f_jk_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "tau = \"tau_cumulant2\"\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15,5))\n",
    "\n",
    "p = sns.kdeplot(df['adjusted_interaction_score_epsilon_or_tau'], ax=axs[0], color=\"blue\")\n",
    "p = sns.kdeplot(df[tau], ax=axs[0], color=\"red\")\n",
    "p.set(xlabel='tau (reported blue, computed red)')\n",
    "\n",
    "p = sns.regplot(x=df[tau],\n",
    "            y=df['adjusted_interaction_score_epsilon_or_tau'],\n",
    "            scatter_kws={'alpha':0.01},\n",
    "            line_kws={'color': 'red'},\n",
    "            ax=axs[1])\n",
    "p.set(xlabel='tau_recalculated', ylabel='tau_reported')\n",
    "axs[1].axline([-0.75, -0.75], [1, 1], linestyle=\"--\", color=\"black\")\n",
    "\n",
    "df[[tau, 'adjusted_interaction_score_epsilon_or_tau']].corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# This logical switch is used to change all downstream analyses\n",
    "\n",
    "use_reported_double_mutant_fitnesses = False\n",
    "compare_to_reported_values = True # if False, compare instead to values recalculated with cumulant formula\n",
    "\n",
    "if use_reported_double_mutant_fitnesses:\n",
    "    multiplicative = \"tau_multiplicative\"\n",
    "    cumulant = \"tau_cumulant\"\n",
    "else:\n",
    "    multiplicative = \"tau_multiplicative2\"\n",
    "    cumulant = \"tau_cumulant2\"\n",
    "\n",
    "if compare_to_reported_values:\n",
    "    compare = \"adjusted_interaction_score_epsilon_or_tau\"\n",
    "else:\n",
    "    compare = cumulant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# To see how outliers vary across scales, we can calculate a significance threshold for the multiplicative scale by \n",
    "# finding the quantile that corresponds +/- 0.08, the trigenic score Kuzmin et al use to find positive/negative outliers.\n",
    "\n",
    "tau_reported_sig_quant, tau_mult_sig_val, tau_iss_sig_val = {},{},{}\n",
    "\n",
    "# get quantiles\n",
    "tau_reported_sig_quant['neg'] = np.mean( np.array(df.adjusted_interaction_score_epsilon_or_tau) < -0.08)\n",
    "tau_reported_sig_quant['pos'] = 1 - np.mean( np.array(df.adjusted_interaction_score_epsilon_or_tau) > 0.08)\n",
    "\n",
    "# calculate significance thresholds on new scales using quantile\n",
    "tau_mult_sig_val['neg'] = np.nanquantile(df[multiplicative], tau_reported_sig_quant['neg'])\n",
    "tau_mult_sig_val['pos'] = np.nanquantile(df[multiplicative], tau_reported_sig_quant['pos'])\n",
    "\n",
    "tau_iss_sig_val['neg'] = np.nanquantile(df[cumulant], tau_reported_sig_quant['neg'])\n",
    "tau_iss_sig_val['pos'] = np.nanquantile(df[cumulant], tau_reported_sig_quant['pos'])\n",
    "\n",
    "print(\"quantiles of the significant values they used\",  tau_reported_sig_quant['neg'], tau_reported_sig_quant['pos'] )\n",
    "print(\"confirming (should be -0.08):\", np.quantile(df.adjusted_interaction_score_epsilon_or_tau, tau_reported_sig_quant['neg']))\n",
    "print(\"confirming (should be 0.08):\", np.quantile(df.adjusted_interaction_score_epsilon_or_tau, tau_reported_sig_quant['pos']))\n",
    "print()\n",
    "print( \"corresponding cutoffs for multiplicative model: \", tau_mult_sig_val['neg'], tau_mult_sig_val['pos'])\n",
    "print( \"corresponding cutoffs for cumulant model: \", tau_iss_sig_val['neg'], tau_iss_sig_val['pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# How do multiplicative values compare to \n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15,5))\n",
    "\n",
    "bw_param =10\n",
    "p = sns.kdeplot(df[multiplicative], ax = axs[0], color=\"red\", log_scale=True)\n",
    "# add one so distributions are more comparable\n",
    "p = sns.kdeplot(df[compare]+1, ax = axs[0], color=\"blue\")\n",
    "axs[0].set_xlim(0.5,2)\n",
    "\n",
    "p = sns.scatterplot(x=df[compare],\n",
    "            y=df[multiplicative],\n",
    "            alpha=0.2,\n",
    "            linewidth=0,\n",
    "            ax=axs[1])\n",
    "p.set(xlabel=compare, ylabel='tau_multiplicative')\n",
    "axs[1].set_xlim(-1,1)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_ylim(0.02,8)\n",
    "axs[1].axhline(tau_mult_sig_val['neg'], color=\"red\", linestyle=\"--\", linewidth=0.5)\n",
    "#axs[1].axhline(tau_mult_sig_val['pos'], color=\"red\", linestyle=\"--\", linewidth=0.5)\n",
    "axs[1].axvline(-0.08, color=\"red\", linestyle=\"--\", linewidth=0.5)\n",
    "#axs[1].axvline(0.08, color=\"red\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "print(df[[multiplicative, compare]].corr(method=\"spearman\"))\n",
    "print(df[[multiplicative, compare]].corr(method=\"kendall\"))\n",
    "print(df[[multiplicative, compare]].corr(method=\"pearson\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def count_frac(df):\n",
    "    return len(df)\n",
    "    \n",
    "results = defaultdict(list)\n",
    "p = 0.05\n",
    "\n",
    "overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment( df[df.pval < p], \"negative\", count_frac, multiplicative, tau_mult_sig_val)\n",
    "denom = overlap + only_reported + only_mult\n",
    "\n",
    "results['type'].extend(['overlap', 'only reported', 'only multiplicative'])\n",
    "results['number'].extend([overlap, only_reported, only_mult])\n",
    "results['fraction'].extend([overlap/denom, only_reported/denom, only_mult/denom])\n",
    "\n",
    "#overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment( df[df.pval < p], \"positive\", count_frac, multiplicative, tau_mult_sig_val)\n",
    "#denom = overlap + only_reported + only_mult\n",
    "\n",
    "#results['type'].extend(['overlap_positive', 'only reported positive', 'only mult positive'])\n",
    "#results['number'].extend([overlap, only_reported, only_mult])\n",
    "#results['fraction'].extend([overlap/denom, only_reported/denom, only_mult/denom])\n",
    "\n",
    "pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#plt.subplot(figsize=(15,15))\n",
    "plt.figure(figsize=(12,12))\n",
    "v = venn2(subsets = (only_mult, only_reported, overlap), set_labels = ('', ''), set_colors=('#b2df8a', '#1f78b4', '#a6cee3'), alpha = 1)\n",
    "#v = venn2(subsets = (only_mult, only_reported, overlap), set_labels = ('multiplicative', 'reported'), set_colors=('#b2df8a', '#1f78b4', '#a6cee3'), alpha = 0.7)\n",
    "#out = venn3([set1, set2, set3], ('Set1', 'Set2', 'Set3'))\n",
    "for text in v.set_labels:\n",
    "    text.set_fontsize(14)\n",
    "for text in v.subset_labels:\n",
    "    text.set_fontsize(40)\n",
    "\n",
    "print(v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# See if outliers are enriched for other biological signals. Here we load in pairwise physical interactions from one of two databases.\n",
    "# 'physical_pairwise_interactions_set' contains a set of sorted 2-tuples of genes particupating in pairwise protein interactions\n",
    "\n",
    "#physical_pairwise_interactions_set = db.get_physical_interactions_yeastGenomeDotOrg()\n",
    "\n",
    "# BIOGRID contains physical interactions measured from a variety of assays including co-localization\n",
    "# see here for explanation of experimental evidence codes: https://wiki.thebiogrid.org/doku.php/experimental_systems\n",
    "db_interactions = db.get_physical_interactions_BIOGRID()\n",
    "experimental_systems = ['Affinity Capture-MS', 'Affinity Capture-Western', 'Two-hybrid', 'Reconstituted Complex', 'PCA', 'Co-purification', 'Co-crystal Structure']\n",
    "#experimental_systems = ['Affinity Capture-RNA']\n",
    "#experimental_systems = ['Biochemical Activity']\n",
    "#experimental_systems = ['Co-localization']\n",
    "#print(db_interactions.experimental_system.value_counts())\n",
    "\n",
    "db_interactions = db_interactions[db_interactions.experimental_system.isin(experimental_systems)]\n",
    "#db_interactions = db_interactions[db_interactions.experimental_system_type == \"physical\"]\n",
    "#db_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "physical_pairwise_interactions_set = db.find_unique_interactions(db_interactions, 'official_symbol_interactor_a', 'official_symbol_interactor_b')\n",
    "num_physical_interactions, oneplus_physical_interactions, twoplus_physical_interactions, three_physical_interactions = db.count_interactions_in_set(df, physical_pairwise_interactions_set)\n",
    "#df['num_physical_interactions'] = df['alleles'].map(num_physical_interactions)\n",
    "#df['twoplus_physical_interactions'] = df['alleles'].map(twoplus_physical_interactions)\n",
    "df['three_physical_interactions'] = df['alleles'].map(three_physical_interactions)\n",
    "\n",
    "#print()\n",
    "#print(df['num_physical_interactions'].value_counts())\n",
    "\n",
    "physical_pairwise_interactions_dict = db.collect_interactions_in_dict(db_interactions, 'official_symbol_interactor_a', 'official_symbol_interactor_b')\n",
    "three_shared_physical_interactions = db.count_shared_interactions_in_dict(df, physical_pairwise_interactions_dict, 1)\n",
    "df['three_shared_physical_interactions'] = df['alleles'].map(three_shared_physical_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment(df[df.pval < p], \"negative\", enrich.fraction_three_shared, multiplicative, tau_mult_sig_val)\n",
    "# since all_mult has more observations than all_reported, treat all_mult as the \"population\" and all_reported as the \"sample\" for the hypergeometric test\n",
    "# and use the hypergeom cdf to do a lower-tailed test\n",
    "test = hypergeom.cdf(*enrich.get_hypergeom_params(only_reported, only_mult))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# arg that goes into get_coexpression_gene_pairs is the z-score associated with how significant the correlation b/t expression is\n",
    "coexpression_gene_pairs_set, divexpression_gene_pairs_set = db.get_expression_gene_pairs(3)\n",
    "\n",
    "num_coex_interactions, oneplus_coex_interactions, twoplus_coex_interactions, three_coex_interactions = db.count_interactions_in_set(df, coexpression_gene_pairs_set)\n",
    "num_divex_interactions, oneplus_divex_interactions, twoplus_divex_interactions, three_divex_interactions = db.count_interactions_in_set(df, divexpression_gene_pairs_set)\n",
    "\n",
    "df['num_coex_interactions'] = df['alleles'].map(num_coex_interactions)\n",
    "df['oneplus_coex_interactions'] = df['alleles'].map(oneplus_coex_interactions)\n",
    "df['twoplus_coex_interactions'] = df['alleles'].map(twoplus_coex_interactions)\n",
    "df['three_coex_interactions'] = df['alleles'].map(three_coex_interactions)\n",
    "\n",
    "df['num_divex_interactions'] = df['alleles'].map(num_divex_interactions)\n",
    "df['oneplus_divex_interactions'] = df['alleles'].map(oneplus_divex_interactions)\n",
    "df['twoplus_divex_interactions'] = df['alleles'].map(twoplus_divex_interactions)\n",
    "df['three_divex_interactions'] = df['alleles'].map(three_divex_interactions)\n",
    "\n",
    "print(df['num_coex_interactions'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"COEXPRESSION ENRICHMENT P-VALUES\")\n",
    "print(enrich.perform_hypergeom_test(df, \"negative\", enrich.fraction_coex_twoplus, multiplicative, tau_mult_sig_val))\n",
    "\n",
    "print(\"GO ENRICHMENT P-VALUES\")\n",
    "print(enrich.perform_hypergeom_test(df, \"negative\", enrich.alleles_2_go_enrichment, multiplicative, tau_mult_sig_val))\n",
    "\n",
    "print(\"SHARED PPI ENRICHMENT P-VALUES\")\n",
    "print(enrich.perform_hypergeom_test(df, \"negative\", enrich.fraction_three_shared, multiplicative, tau_mult_sig_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"DIRECTLY COMPARE MULT AND REPORTED\")\n",
    "print(\"GO ENRICHMENT\")\n",
    "overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment(df[df.pval < p], \"negative\", enrich.alleles_2_go_enrichment, multiplicative, tau_mult_sig_val)\n",
    "# since all_mult has more observations than all_reported, treat all_mult as the \"population\" and all_reported as the \"sample\" for the hypergeometric test\n",
    "# and use the hypergeom cdf to do a lower-tailed test\n",
    "test = hypergeom.cdf(*enrich.get_hypergeom_params(all_reported, all_mult))\n",
    "print(test)\n",
    "\n",
    "print(\"shared PPI\")\n",
    "overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment(df[df.pval < p], \"negative\", enrich.fraction_three_shared, multiplicative, tau_mult_sig_val)\n",
    "# since all_mult has more observations than all_reported, treat all_mult as the \"population\" and all_reported as the \"sample\" for the hypergeometric test\n",
    "# and use the hypergeom cdf to do a lower-tailed test\n",
    "test = hypergeom.cdf(*enrich.get_hypergeom_params(all_reported, all_mult))\n",
    "print(test)\n",
    "\n",
    "print(\"COEXPRESSION\")\n",
    "overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment(df[df.pval < p], \"negative\", enrich.fraction_coex_twoplus, multiplicative, tau_mult_sig_val)\n",
    "# since all_mult has more observations than all_reported, treat all_mult as the \"population\" and all_reported as the \"sample\" for the hypergeometric test\n",
    "# and use the hypergeom cdf to do a lower-tailed test\n",
    "print(all_mult)\n",
    "print(all_reported)\n",
    "test = hypergeom.cdf(*enrich.get_hypergeom_params(all_reported, all_mult))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment(df[df.pval < p], \"negative\", enrich.fraction_coex_twoplus, multiplicative, tau_mult_sig_val)\n",
    "# since all_mult has more observations than all_reported, treat all_mult as the \"population\" and all_reported as the \"sample\" for the hypergeometric test\n",
    "# and use the hypergeom cdf to do a lower-tailed test\n",
    "print(all_mult)\n",
    "print(all_reported)\n",
    "test = hypergeom.cdf(*enrich.get_hypergeom_params(all_reported, all_mult))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "p = 0.05\n",
    "data1 = []\n",
    "data2 = []\n",
    "funcs = [enrich.fraction_coex_twoplus, enrich.fraction_three_shared, enrich.alleles_2_go_enrichment]\n",
    "for func in funcs:\n",
    "    genome_wide = func(df)\n",
    "    overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment(df[df.pval < p], \"negative\", func, multiplicative, tau_mult_sig_val)\n",
    "    d1 = [overlap['frac']/genome_wide['frac'], only_reported['frac']/genome_wide['frac'], only_mult['frac']/genome_wide['frac']]\n",
    "    d2 = [all_reported['frac']/genome_wide['frac'], all_mult['frac']/genome_wide['frac']]\n",
    "    data1.append(d1)\n",
    "    data2.append(d2)\n",
    "\n",
    "data1 = np.transpose(data1)\n",
    "data2 = np.transpose(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# data: \n",
    "# rows are data category (overlap, only reported, only mult),\n",
    "# cols are analysis (coex, PPI, GO)\n",
    "x = np.arange(len(data1[0]))\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x-width, data1[0], width, color='#a6cee3') # plots first analysis across all data categories (coex, PPI, GO)\n",
    "plt.bar(x, data1[1], width, color='#1f78b4')\n",
    "plt.bar(x+width, data1[2], width, color='#b2df8a')\n",
    "\n",
    "plt.xticks(x, ['coex', 'shared PPI', 'GO enrichment'])\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Fold enrichment\")\n",
    "plt.legend([\"overlap\", \"only reported\", \"only multiplicative\"])\n",
    "#plt.title(\"Negative interactions\")\n",
    "plt.axhline(1, linestyle=\"--\", color=\"gray\")\n",
    "sns.despine()\n",
    "\n",
    "# add annotations for statistical significance\n",
    "analyses = [\"coex\", \"ppi\", \"go\"]\n",
    "for column in range(len(data1[0])):\n",
    "    analysis = analyses[column]\n",
    "    if dataset == \"Kuzmin2020\":\n",
    "        # for 2020 data:\n",
    "        # overlap and only_mult significant for all analyses, only_reported not significant for all analyses\n",
    "        plt.text(column-width, data1[0][column]+0.02, \"*\", ha='center', va='bottom')\n",
    "        plt.text(column, data1[1][column]+0.02, \"ns\", ha='center', va='bottom')\n",
    "        plt.text(column+width, data1[2][column]+0.02, \"*\", ha='center', va='bottom')\n",
    "    elif dataset == \"Kuzmin2018\":\n",
    "        # for 2018 data:\n",
    "        # overlap significant for all, only_mult significant only for GO and PPI, only_reported only significant for GO\n",
    "        if analysis == \"coex\":\n",
    "            plt.text(column-width, data1[0][column]+0.02, \"*\", ha='center', va='bottom') # overlap\n",
    "            plt.text(column, data1[1][column]+0.02, \"ns\", ha='center', va='bottom') # only_reported\n",
    "            plt.text(column+width, data1[2][column]+0.02, \"ns\", ha='center', va='bottom') # only_mult  \n",
    "        if analysis == \"ppi\":\n",
    "            plt.text(column-width, data1[0][column]+0.02, \"*\", ha='center', va='bottom') # overlap\n",
    "            plt.text(column, data1[1][column]+0.02, \"ns\", ha='center', va='bottom') # only_reported\n",
    "            plt.text(column+width, data1[2][column]+0.02, \"*\", ha='center', va='bottom') # only_mult\n",
    "        if analysis == \"go\":\n",
    "            plt.text(column-width, data1[0][column]+0.02, \"*\", ha='center', va='bottom') # overlap\n",
    "            plt.text(column, data1[1][column]+0.02, \"*\", ha='center', va='bottom') # only_reported\n",
    "            plt.text(column+width, data1[2][column]+0.02, \"*\", ha='center', va='bottom') # only_mult\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# data: \n",
    "# rows are data category (overlap, only reported, only mult),\n",
    "# cols are analysis (coex, PPI, GO)\n",
    "x = np.arange(len(data2[0]))\n",
    "width = 0.2\n",
    "\n",
    "# plots first analysis across all data categories (coex, PPI, GO)\n",
    "plt.bar(x-width, data2[0], width*2, color='#1f78b4')\n",
    "plt.bar(x+width, data2[1], width*2, color='#b2df8a')\n",
    "\n",
    "plt.xticks(x, ['coex', 'shared PPI', 'GO enrichment'])\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Fold enrichment\")\n",
    "plt.legend([\"all reported\", \"all multiplicative\",])\n",
    "#plt.title(\"Negative interactions\")\n",
    "plt.axhline(1, linestyle=\"--\", color=\"gray\")\n",
    "sns.despine()\n",
    "\n",
    "\n",
    "x1s = [-0.2, 0.8, 1.8]\n",
    "x2s = [0.2, 1.2, 2.2]\n",
    "addtl_height = 0.5\n",
    "analyses = [\"coex\", \"ppi\", \"go\"]\n",
    "for x1,x2,row in zip(x1s, x2s, x):\n",
    "    analysis = analyses[row]\n",
    "    y, h = np.max(data2[:,row]) + addtl_height, 0.1\n",
    "    plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=\"black\")\n",
    "    # for 2020 data set, all_mult more significant for GO and PPI but not COEX\n",
    "    if dataset == \"Kuzmin2020\":\n",
    "        if analysis == \"coex\":\n",
    "            plt.text((x1+x2)/2, y+h, \"ns\", ha='center', va='bottom', color=\"black\")\n",
    "        else:\n",
    "            plt.text((x1+x2)/2, y+h, \"*\", ha='center', va='bottom', color=\"black\")\n",
    "    elif dataset == \"Kuzmin2018\":\n",
    "        if analysis == \"ppi\":\n",
    "            plt.text((x1+x2)/2, y+h, \"*\", ha='center', va='bottom', color=\"black\")\n",
    "        else:\n",
    "            plt.text((x1+x2)/2, y+h, \"ns\", ha='center', va='bottom', color=\"black\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "funcs =  enrich.alleles_2_go_enrichment\n",
    "genome_wide = func(df)\n",
    "overlap, only_reported, only_mult, all_reported, all_mult = enrich.outlier_enrichment(df[df.pval < p], \"negative\", func, multiplicative, tau_mult_sig_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(all_mult['frac']/genome_wide['frac'])\n",
    "print(all_reported['frac']/genome_wide['frac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(all_mult['frac'])\n",
    "print(all_reported['frac'])\n",
    "print(genome_wide['frac'])\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#tmp = df[(df.pval <= 0.05) & (df[multiplicative] <= tau_mult_sig_val['neg'])]\n",
    "overlap = df[(df.pval <= 0.05) & (df.adjusted_interaction_score_epsilon_or_tau <= -0.08) & (df[multiplicative] <= tau_mult_sig_val['neg'])]\n",
    "only_mult = df[(df.pval <= 0.05) & (df.adjusted_interaction_score_epsilon_or_tau > -0.08) & (df[multiplicative] <= tau_mult_sig_val['neg'])]\n",
    "only_reported = df[(df.pval <= 0.05) & (df.adjusted_interaction_score_epsilon_or_tau <= -0.08) & (df[multiplicative] > tau_mult_sig_val['neg'])]\n",
    "\n",
    "print(len(overlap))\n",
    "print(len(only_mult))\n",
    "print(len(only_reported))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# COMPARES NUMBER OF GENE IN only_reported OR only_mult TO RANDOM\n",
    "reps = 100\n",
    "\n",
    "def unique_genes(df):\n",
    "    genes = set()\n",
    "    for i,r in df.iterrows():\n",
    "        a = r['alleles'].split(',')\n",
    "        a = [i.split('-')[0] for i in a]\n",
    "        [genes.add(i) for i in a]\n",
    "    return genes\n",
    "\n",
    "test_set = only_mult\n",
    "\n",
    "overlap_unique_genes = unique_genes(overlap)\n",
    "print(\"genes in overlap:\", len(overlap_unique_genes))\n",
    "\n",
    "genes_in_random_samples = []\n",
    "for i in range(reps):\n",
    "    tmp = overlap_unique_genes.copy()\n",
    "    rand_samp = unique_genes(df.sample(n=len(test_set), replace=False))\n",
    "    [tmp.add(i) for i in rand_samp]\n",
    "    genes_in_random_samples.append( len(tmp) ) \n",
    "print(\"min rand_samp:\", min(genes_in_random_samples))\n",
    "\n",
    "tmp = overlap_unique_genes.copy()\n",
    "[tmp.add(i) for i in unique_genes(test_set)]\n",
    "print(\"adding test_set:\", len(tmp))\n",
    "\n",
    "pl = sns.histplot(genes_in_random_samples, bins=10)\n",
    "pl.axvline(len(tmp), linestyle=\"--\", color=\"red\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# COMPARES only_reported TO only_mult DIRECtlAY VIA SUBSAMPLING APPROACH\n",
    "\n",
    "reported_unique_genes = overlap_unique_genes.copy()\n",
    "[reported_unique_genes.add(i) for i in unique_genes(only_reported)]\n",
    "print(len(reported_unique_genes))\n",
    "\n",
    "# randomly subsample from only_mult\n",
    "genes_in_random_samples = []\n",
    "for i in range(reps):\n",
    "    tmp = overlap_unique_genes.copy()\n",
    "    rand_samp = unique_genes(only_mult.sample(n=len(only_reported), replace=False))\n",
    "    [tmp.add(i) for i in rand_samp]\n",
    "    genes_in_random_samples.append( len(tmp) ) \n",
    "#print(\"min rand_samp:\", min(genes_in_random_samples))\n",
    "\n",
    "pl = sns.histplot(genes_in_random_samples, bins=10)\n",
    "pl.axvline(len(reported_unique_genes), linestyle=\"--\", color=\"red\")\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(20,5))\n",
    "\n",
    "alph = 0.8\n",
    "lw = 0.1\n",
    "bin_wid = 0.02\n",
    "sns.scatterplot(x = overlap.adjusted_interaction_score_epsilon_or_tau,\n",
    "                y=overlap[multiplicative],\n",
    "                alpha=alph,\n",
    "                linewidth=lw,\n",
    "                edgecolor=\"black\",\n",
    "                color='#a6cee3',\n",
    "                ax=axs[0])\n",
    "sns.scatterplot(x=only_mult.adjusted_interaction_score_epsilon_or_tau,\n",
    "                y=only_mult[multiplicative],\n",
    "                alpha=alph,\n",
    "                linewidth=lw,\n",
    "                edgecolor=\"black\",               \n",
    "                color=\"#b2df8a\",\n",
    "                ax=axs[0])\n",
    "sns.scatterplot(x=only_reported.adjusted_interaction_score_epsilon_or_tau,\n",
    "                y=only_reported[multiplicative],\n",
    "                alpha=alph,\n",
    "                linewidth=lw,\n",
    "                edgecolor=\"black\",\n",
    "                color=\"#1f78b4\",\n",
    "                ax=axs[0])\n",
    "axs[0].axvline(-0.08, linestyle=\"--\", color=\"black\")\n",
    "axs[0].axhline(tau_mult_sig_val['neg'], linestyle=\"--\", color=\"black\")\n",
    "axs[0].set(xlabel=\"reported value\", ylabel='multiplicative value')\n",
    "\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "\n",
    "\n",
    "sns.histplot(overlap, x=multiplicative, ax=axs[1], stat='probability', binwidth=bin_wid, color=\"#a6cee3\", element='step', edgecolor=\"black\")\n",
    "sns.histplot(only_mult, x=multiplicative, ax=axs[1], stat='probability', binwidth=bin_wid, color=\"#b2df8a\", element='step', edgecolor=\"black\")\n",
    "axs[1].set(xlabel='multiplicative value')\n",
    "\n",
    "\n",
    "sns.histplot(overlap, x='adjusted_interaction_score_epsilon_or_tau', ax=axs[2], stat='probability', binwidth=bin_wid, color=\"#a6cee3\", element='step', edgecolor=\"black\")\n",
    "sns.histplot(only_reported, x='adjusted_interaction_score_epsilon_or_tau', ax=axs[2], stat='probability', binwidth=bin_wid, color=\"#1f78b4\", element='step', edgecolor=\"black\")\n",
    "axs[2].set(xlabel='reported value')\n",
    "\n",
    "if dataset == \"Kuzmin2018\":\n",
    "    axs[0].set_ylim(0,1.75)\n",
    "    axs[0].set_xlim(-1.1,0.08)\n",
    "    axs[1].set_ylim(0,0.4)\n",
    "    axs[1].set_xlim(0,1.0)\n",
    "\n",
    "    axs[2].set_ylim(0,0.4)\n",
    "\n",
    "elif dataset == \"Kuzmin2020\":\n",
    "    axs[0].set_ylim(0,1.2)\n",
    "    axs[0].set_xlim(-0.8,0.3)\n",
    "    axs[1].set_ylim(0,0.5)\n",
    "    axs[1].set_xlim(0,1.0)\n",
    "\n",
    "    axs[2].set_ylim(0,0.5)\n",
    "#print(overlap[[multiplicative, compare]].corr(method=\"spearman\"))\n",
    "#print(overlap[[multiplicative, compare]].corr(method=\"kendall\"))\n",
    "#print(overlap[[multiplicative, compare]].corr(method=\"pearson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "x = only_mult.alleles\n",
    "y = only_reported.alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('epistasis_reanalysis')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n epistasis_reanalysis ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('epistasis_reanalysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dff2ece025a6501398ce7c961fb28035c9eaf324e39ce0f82e368350afa5e194"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
